## Papers

<details>
  <summary></summary>
  [Link]()
  
  ##### 
  
</details>

<details>
  <summary>Detecting and Tracking Political Abuse in Social Medias</summary>
  [Link](https://ojs.aaai.org/index.php/ICWSM/article/view/14127/13976)
  
  ##### Purpose
  The main purpose of the paper is to detect and track the political memes (here memes means hastags, mentions, tweets etc) are being astroturfed. The difference between astroturfed and spam is : primary object of spammer is to persuade users to click a link, someone interested in promoting an astroturf message wants to establish a false sense of group consesus about a particular idea. Related to this process is the fact that users are more likely to believe a message that they perceive as coming from several independent sources, or from an acquaintance. Spam detection systems often focus on the content of a potential spam message - for instance to see if the messages contains a certain link or set of tags. 
  
</details>

<details>
  <summary>Content-based features predict social media influence operations</summary>
  [Link](https://www.science.org/doi/full/10.1126/sciadv.abb5824)(file:///home/manita/carl/plots/abb5824_sm%20(1).pdf)
  
  ##### A machine learning framework to predict
  Task 1: Use the activity data in month t and predict the activity over time <br />
  Task 2: Identify social media posts from troll accounts in month t using data on troll activity in month t -1. Did not use creation date features to avoid easy detection based on user-identifiable features. <br />
  Task 3: Find social media posts from troll accounts in month t that have not posted in month t-1 using data on troll activity in month t -1. This test how similar past content is to the content produced by new troll accounts in the current period, which is effectively an indicator of whether those operating new accounts are using the same tactics, techniques, and procedures as those operating existing accounts. <br />
  Task 4: Detect activity across different data releases by platforms that were leveraging backend signals and manual investigation to find influence campaigns. <br />
  Task 5: Identify social media posts from trolls in month t on a given platform using data on troll activity in month t on another platform. <br /> <br />
  
  Feature importance change with time indicating the strategy change with time.
  
</details>

<details>
  <summary>Engaging with Others: How the IRA Coordinated Information Operation Made Friends</summary>
  [Link](https://misinforeview.hks.harvard.edu/wp-content/uploads/2020/04/FORMATTED_article_PatrickDarren.pdf)
  
  ##### Findings
  
  External accounts in information operations were central to every stage of the IO's operation, from introudcton to growth and finally to a stage in which amplification of external accounts wa as an important IRA goal. "This research supports Starbird et al's (2019) observation regarding the importance of considering
"the role of online crowds (unwitting and otherwise) in spreading disinformation and political
propaganda" (p. 4)". <br /> <br />
  **Finding 1** : Three sets of IRA thematic accounts (Right Trolls, Left Trolls, and Hashtag Gamers) made extensive use of networked output, throughout the campaign, both internally and externally. <br />
  **Finding 2** : Replies were used primarily early in the life of the troll accounts and early in the campaign. <br />
  **Finding 3** : After this introductory period, the mix shifts to approximately half original content and half external retweets. During this “growth” period, troll accounts substantially increase followers. <br />
 **Finding 4** : In Sep-Oct, 2016, the mix for Left and Right Trolls shifts again to over 90 percent external retweets. <br />
 **Finding 5** : External accounts targeted in this way were thematically aligned with the troll accounts
  
  **Summary** : External accounts were targeted by replying, retweeting during specific timing of the operation. The targeted accounts aligned with the ideology of the troll accounts.
 </details>

<details>
  <summary>Political Astroturfing on Twitter: How to Coordinate a Disinformation Campagin</summary>
  [Link](https://www.tandfonline.com/doi/full/10.1080/10584609.2019.1661888)
  
  ##### What is political astroturfing? <br />
 **Political Astroturfing** : a centrally coordinated disinformation campaign in which participants pretend to be ordinary citizens acting independently , has the potential to influence electoral outcomes and other forms of political behavior.
  
</details>
