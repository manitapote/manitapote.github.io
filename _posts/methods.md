
<details>
  <summary></summary>
  [Link]()
  
  ##### 
  
</details>

<details>
  <summary>Hypothesis Testing</summary>
  [Link](Think Stats)
  
  ##### Classical Hypothesis Testing
  - The first step is to quantify the size of the apparent effect by choosing a test statistis. For example: test statistics could be difference in mean between two group, Chi square test statistics
  - Define null hypothesis, which is a model of the system based on the assumption that the apparent effect is not real.
  - Third step is to compute a p-value which is the probability of seeing the apparent effect if the null hypothesis is true. (the probability of seeing a difference as big or bigger under the null hypothesis)
  - Interpret the result, if the p-value is low the effect is said to be statistically significant.
  
  ##### Error 
  An effect is considered statistically significant if the p-value is below some threshold, commonly 5%. This procedure raises two questions. 
  - If the effect is actually due to chance what is the probability that we will wrongly consider it significant? The probability is the **false positive rate**.
  - If the effect is real, what is the chance that the hypothesis test will fail? This probability is the **false negative rate**.
  
  If the threshold is 5%, the false positive rate is 5%.
  
  ##### Power
  The false negative rate is harder to compute because it depends on the actual effect size and normally we don't know that. One option is to compute a rate conditioned on a hypothetical effect size.
  
</details>

### Cohen's Kappa
### Fleiss K
### Welch's t-test
### Chi-squared test


